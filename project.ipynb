{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4bed4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\python310\\lib\\site-packages\\torchtext\\data\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"d:\\python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"d:\\python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\tomin\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\tomin\\AppData\\Roaming\\Python\\Python310\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\tomin\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\tomin\\AppData\\Roaming\\Python\\Python310\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"d:\\python310\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"d:\\python310\\lib\\asyncio\\base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"d:\\python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\tomin\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\utils.py\", line 71, in preserve_context\n",
      "    return await f(*args, **kwargs)\n",
      "  File \"C:\\Users\\tomin\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n",
      "    await self.dispatch_shell(msg, subshell_id=subshell_id)\n",
      "  File \"C:\\Users\\tomin\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\tomin\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"C:\\Users\\tomin\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\tomin\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\tomin\\AppData\\Roaming\\Python\\Python310\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\tomin\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\tomin\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\tomin\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\tomin\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\tomin\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\tomin\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\tomin\\AppData\\Local\\Temp\\ipykernel_19576\\3137393902.py\", line 11, in <module>\n",
      "    import underthesea\n",
      "  File \"d:\\python310\\lib\\site-packages\\underthesea\\__init__.py\", line 63, in <module>\n",
      "    globals()[name] = get_optional_import(module, name)\n",
      "  File \"d:\\python310\\lib\\site-packages\\underthesea\\__init__.py\", line 56, in get_optional_import\n",
      "    module = __import__(module_name, fromlist=[object_name])\n",
      "  File \"d:\\python310\\lib\\site-packages\\underthesea\\pipeline\\dependency_parse\\__init__.py\", line 2, in <module>\n",
      "    from underthesea.models.dependency_parser import DependencyParser\n",
      "  File \"d:\\python310\\lib\\site-packages\\underthesea\\models\\dependency_parser.py\", line 19, in <module>\n",
      "    import underthesea.modules.nn\n",
      "  File \"d:\\python310\\lib\\site-packages\\underthesea\\modules\\nn.py\", line 7, in <module>\n",
      "    from underthesea.utils.util_deep_learning import device\n",
      "  File \"d:\\python310\\lib\\site-packages\\underthesea\\utils\\util_deep_learning.py\", line 11, in <module>\n",
      "    device = torch.device(\"cpu\")\n",
      "d:\\python310\\lib\\site-packages\\underthesea\\utils\\util_deep_learning.py:11: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device = torch.device(\"cpu\")\n",
      "d:\\python310\\lib\\site-packages\\torchtext\\vocab\\__init__.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n",
      "d:\\python310\\lib\\site-packages\\torchtext\\utils.py:4: UserWarning: \n",
      "/!\\ IMPORTANT WARNING ABOUT TORCHTEXT STATUS /!\\ \n",
      "Torchtext is deprecated and the last released version will be 0.18 (this one). You can silence this warning by calling the following at the beginnign of your scripts: `import torchtext; torchtext.disable_torchtext_deprecation_warning()`\n",
      "  warnings.warn(torchtext._TORCHTEXT_DEPRECATION_MSG)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# # from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer\n",
    "# import re\n",
    "# import torch\n",
    "# import torchtext\n",
    "# from typing import Iterable\n",
    "# from torchtext.data.utils import get_tokenizer\n",
    "# import underthesea\n",
    "# from torchtext.vocab import build_vocab_from_iterator\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b3a2119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>vietnamese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Today is June 18th and it is Muiriel's birthday!</td>\n",
       "      <td>Hôm nay là ngày 18 tháng sáu, và cũng là ngày ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Muiriel is 20 now.</td>\n",
       "      <td>Bây giờ Muiriel được 20 tuổi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The password is \"Muiriel\".</td>\n",
       "      <td>Mật mã là \"Muiriel\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm at a loss for words.</td>\n",
       "      <td>Tôi hết lời để nói.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm at a loss for words.</td>\n",
       "      <td>Tôi không biết nói gì.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            english  \\\n",
       "0  Today is June 18th and it is Muiriel's birthday!   \n",
       "1                                Muiriel is 20 now.   \n",
       "2                        The password is \"Muiriel\".   \n",
       "3                          I'm at a loss for words.   \n",
       "4                          I'm at a loss for words.   \n",
       "\n",
       "                                          vietnamese  \n",
       "0  Hôm nay là ngày 18 tháng sáu, và cũng là ngày ...  \n",
       "1                      Bây giờ Muiriel được 20 tuổi.  \n",
       "2                               Mật mã là \"Muiriel\".  \n",
       "3                                Tôi hết lời để nói.  \n",
       "4                             Tôi không biết nói gì.  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Sentence pairs in English-Vietnamese - 2025-11-12.tsv', sep='\\t')\n",
    "df.columns = ['eng_id', 'english', 'vie_id', 'vietnamese']\n",
    "df = df[['english', 'vietnamese']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b20e5501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>vietnamese</th>\n",
       "      <th>eng_tokens</th>\n",
       "      <th>vie_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Today is June 18th and it is Muiriel's birthday!</td>\n",
       "      <td>Hôm nay là ngày 18 tháng sáu, và cũng là ngày ...</td>\n",
       "      <td>[Today, is, June, 18th, and, it, is, Muiriel, ...</td>\n",
       "      <td>[Hôm nay, là, ngày, 18, tháng, sáu, ,, và, cũn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Muiriel is 20 now.</td>\n",
       "      <td>Bây giờ Muiriel được 20 tuổi.</td>\n",
       "      <td>[Muiriel, is, 20, now, .]</td>\n",
       "      <td>[Bây giờ, Muiriel, được, 20, tuổi, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The password is \"Muiriel\".</td>\n",
       "      <td>Mật mã là \"Muiriel\".</td>\n",
       "      <td>[The, password, is, ``, Muiriel, '', .]</td>\n",
       "      <td>[Mật mã, là, \", Muiriel, \", .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm at a loss for words.</td>\n",
       "      <td>Tôi hết lời để nói.</td>\n",
       "      <td>[I, 'm, at, a, loss, for, words, .]</td>\n",
       "      <td>[Tôi, hết, lời, để, nói, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm at a loss for words.</td>\n",
       "      <td>Tôi không biết nói gì.</td>\n",
       "      <td>[I, 'm, at, a, loss, for, words, .]</td>\n",
       "      <td>[Tôi, không, biết, nói, gì, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            english  \\\n",
       "0  Today is June 18th and it is Muiriel's birthday!   \n",
       "1                                Muiriel is 20 now.   \n",
       "2                        The password is \"Muiriel\".   \n",
       "3                          I'm at a loss for words.   \n",
       "4                          I'm at a loss for words.   \n",
       "\n",
       "                                          vietnamese  \\\n",
       "0  Hôm nay là ngày 18 tháng sáu, và cũng là ngày ...   \n",
       "1                      Bây giờ Muiriel được 20 tuổi.   \n",
       "2                               Mật mã là \"Muiriel\".   \n",
       "3                                Tôi hết lời để nói.   \n",
       "4                             Tôi không biết nói gì.   \n",
       "\n",
       "                                          eng_tokens  \\\n",
       "0  [Today, is, June, 18th, and, it, is, Muiriel, ...   \n",
       "1                          [Muiriel, is, 20, now, .]   \n",
       "2            [The, password, is, ``, Muiriel, '', .]   \n",
       "3                [I, 'm, at, a, loss, for, words, .]   \n",
       "4                [I, 'm, at, a, loss, for, words, .]   \n",
       "\n",
       "                                          vie_tokens  \n",
       "0  [Hôm nay, là, ngày, 18, tháng, sáu, ,, và, cũn...  \n",
       "1              [Bây giờ, Muiriel, được, 20, tuổi, .]  \n",
       "2                     [Mật mã, là, \", Muiriel, \", .]  \n",
       "3                        [Tôi, hết, lời, để, nói, .]  \n",
       "4                     [Tôi, không, biết, nói, gì, .]  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['eng_tokens'] = df['english'].apply(nltk.word_tokenize) \n",
    "df['vie_tokens'] = df['vietnamese'].apply(underthesea.word_tokenize) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "025118ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_LANGUAGE = 'en'\n",
    "TGT_LANGUAGE = 'vi'\n",
    "\n",
    "def data_iterator(df) -> Iterable:\n",
    "    for _, row in df.iterrows():\n",
    "        yield (row['english'], row['vietnamese'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c600b0cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m token_transform \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m----> 2\u001b[0m token_transform[SRC_LANGUAGE] \u001b[38;5;241m=\u001b[39m \u001b[43mget_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspacy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43men_core_web_sm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m token_transform[TGT_LANGUAGE] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: underthesea\u001b[38;5;241m.\u001b[39mword_tokenize(x, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msplit()\n",
      "File \u001b[1;32md:\\python310\\lib\\site-packages\\torchtext\\data\\utils.py:94\u001b[0m, in \u001b[0;36mget_tokenizer\u001b[1;34m(tokenizer, language)\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 94\u001b[0m     spacy \u001b[38;5;241m=\u001b[39m \u001b[43mspacy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m:\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;66;03m# Model shortcuts no longer work in spaCy 3.0+, try using fullnames\u001b[39;00m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;66;03m# List is from https://github.com/explosion/spaCy/blob/b903de3fcb56df2f7247e5b6cfa6b66f4ff02b62/spacy/errors.py#L789\u001b[39;00m\n\u001b[0;32m     98\u001b[0m     OLD_MODEL_SHORTCUTS \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     99\u001b[0m         spacy\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mOLD_MODEL_SHORTCUTS \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(spacy\u001b[38;5;241m.\u001b[39merrors, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOLD_MODEL_SHORTCUTS\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m    100\u001b[0m     )\n",
      "File \u001b[1;32md:\\python310\\lib\\site-packages\\spacy\\__init__.py:52\u001b[0m, in \u001b[0;36mload\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mload\u001b[39m(\n\u001b[0;32m     29\u001b[0m     name: Union[\u001b[38;5;28mstr\u001b[39m, Path],\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m     config: Union[Dict[\u001b[38;5;28mstr\u001b[39m, Any], Config] \u001b[38;5;241m=\u001b[39m util\u001b[38;5;241m.\u001b[39mSimpleFrozenDict(),\n\u001b[0;32m     36\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Language:\n\u001b[0;32m     37\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    name (str): Package name or model path.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43menable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\python310\\lib\\site-packages\\spacy\\util.py:531\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE941\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname, full\u001b[38;5;241m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[38;5;66;03m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m--> 531\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE050\u001b[38;5;241m.\u001b[39mformat(name\u001b[38;5;241m=\u001b[39mname))\n",
      "\u001b[1;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
     ]
    }
   ],
   "source": [
    "token_transform = {}\n",
    "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "token_transform[TGT_LANGUAGE] = lambda x: underthesea.word_tokenize(x, format='text').split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ebd071",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "vocab_transform = {}\n",
    "\n",
    "def yield_tokens(data_iter: Iterable, language: str):\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "    for data_sample in data_iter:\n",
    "        yield token_transform[language](data_sample[language_index[language]])\n",
    "\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    vocab_transform[ln] = build_vocab_from_iterator(\n",
    "        yield_tokens(data_iterator(df), ln),\n",
    "        min_freq=1,\n",
    "        specials=special_symbols,\n",
    "        special_first=True\n",
    "    )\n",
    "    vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a7c78b",
   "metadata": {},
   "source": [
    "Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41754e64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
