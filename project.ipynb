{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4bed4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from transformers import TFAutoModelForSeq2SeqLM, AutoTokenizer\n",
    "import re\n",
    "from typing import Iterable\n",
    "from torchtext.data import get_tokenizer\n",
    "import underthesea\n",
    "from torchtext.vocab import build_vocab_from_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b3a2119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>english</th>\n",
       "      <th>vietnamese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Today is June 18th and it is Muiriel's birthday!</td>\n",
       "      <td>Hôm nay là ngày 18 tháng sáu, và cũng là ngày ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Muiriel is 20 now.</td>\n",
       "      <td>Bây giờ Muiriel được 20 tuổi.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The password is \"Muiriel\".</td>\n",
       "      <td>Mật mã là \"Muiriel\".</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I'm at a loss for words.</td>\n",
       "      <td>Tôi hết lời để nói.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I'm at a loss for words.</td>\n",
       "      <td>Tôi không biết nói gì.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            english  \\\n",
       "0  Today is June 18th and it is Muiriel's birthday!   \n",
       "1                                Muiriel is 20 now.   \n",
       "2                        The password is \"Muiriel\".   \n",
       "3                          I'm at a loss for words.   \n",
       "4                          I'm at a loss for words.   \n",
       "\n",
       "                                          vietnamese  \n",
       "0  Hôm nay là ngày 18 tháng sáu, và cũng là ngày ...  \n",
       "1                      Bây giờ Muiriel được 20 tuổi.  \n",
       "2                               Mật mã là \"Muiriel\".  \n",
       "3                                Tôi hết lời để nói.  \n",
       "4                             Tôi không biết nói gì.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Sentence pairs in English-Vietnamese - 2025-11-12.tsv', sep='\\t')\n",
    "df.columns = ['eng_id', 'english', 'vie_id', 'vietnamese']\n",
    "df = df[['english', 'vietnamese']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20e5501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please install SpaCy. See the docs at https://spacy.io for more information.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m token_transform = {}\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m token_transform[SRC_LANGUAGE] = \u001b[43mget_tokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mspacy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43men_core_web_sm\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m token_transform[TGT_LANGUAGE] = get_tokenizer(\u001b[33m'\u001b[39m\u001b[33mspacy\u001b[39m\u001b[33m'\u001b[39m, language=\u001b[33m'\u001b[39m\u001b[33mvi_core_news_sm\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m df.head()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\python\\Lib\\site-packages\\torchtext\\data\\utils.py:113\u001b[39m, in \u001b[36mget_tokenizer\u001b[39m\u001b[34m(tokenizer, language)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tokenizer == \u001b[33m\"\u001b[39m\u001b[33mspacy\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    112\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m         \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mspacy\u001b[39;00m\n\u001b[32m    114\u001b[39m         spacy = spacy.load(language)\n\u001b[32m    115\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m partial(_spacy_tokenize, spacy=spacy)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "df['eng_tokens'] = df['english'].apply(nltk.word_tokenize) \n",
    "df['vie_tokens'] = df['vietnamese'].apply(underthesea.word_tokenize) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025118ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "SRC_LANGUAGE = 'en'\n",
    "TGT_LANGUAGE = 'vi'\n",
    "\n",
    "def data_iterator(df) -> Iterable:\n",
    "    for _, row in df.iterrows():\n",
    "        yield (row['english'], row['vietnamese'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c600b0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_transform = {}\n",
    "token_transform[SRC_LANGUAGE] = get_tokenizer('spacy', language='en_core_web_sm')\n",
    "token_transform[TGT_LANGUAGE] = lambda x: underthesea.word_tokenize(x, format='text').split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ebd071",
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK_IDX, PAD_IDX, BOS_IDX, EOS_IDX = 0, 1, 2, 3\n",
    "special_symbols = ['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "\n",
    "vocab_transform = {}\n",
    "\n",
    "def yield_tokens(data_iter: Iterable, language: str):\n",
    "    language_index = {SRC_LANGUAGE: 0, TGT_LANGUAGE: 1}\n",
    "    for data_sample in data_iter:\n",
    "        yield token_transform[language](data_sample[language_index[language]])\n",
    "\n",
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "    vocab_transform[ln] = build_vocab_from_iterator(\n",
    "        yield_tokens(data_iterator(df), ln),\n",
    "        min_freq=1,\n",
    "        specials=special_symbols,\n",
    "        special_first=True\n",
    "    )\n",
    "    vocab_transform[ln].set_default_index(UNK_IDX)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
